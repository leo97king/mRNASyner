{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open('D:/unilm/data/hg38_mrna.fasta','r')\n",
    "f2=open('D:/unilm/data/mrna.txt','w')\n",
    "#a=f1.readlines()\n",
    "s=0\n",
    "for lines in f1.readlines():\n",
    "    if '>' in lines:\n",
    "        s=s+1\n",
    "        if s == 1:\n",
    "            continue\n",
    "        else:\n",
    "            f2.write('\\n')\n",
    "            continue\n",
    "    f2.write(lines.strip('\\n'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对输入的fasta格式文件筛选，选取<1500长度的UTR且<6000长度的CDS序列作为数据集\n",
    "f2=open('D:/unilm/data/mrna.txt','r')\n",
    "f3=open('D:/unilm/data/mrna_final.txt','w')\n",
    "for lines in f2.readlines():\n",
    "    list_5utr=[]\n",
    "    list_cds=[]\n",
    "    list_3utr=[]\n",
    "    y=0\n",
    "    for strings in lines:\n",
    "        if strings.isupper():\n",
    "            list_cds.append(strings)\n",
    "            y=y+1\n",
    "            continue\n",
    "        if y != 0 :\n",
    "            if strings.islower():\n",
    "                list_3utr.append(strings)\n",
    "                continue\n",
    "        list_5utr.append(strings)                   \n",
    "    if len(list_5utr) <= 1500 and len(list_5utr) >1 and len(list_cds) <= 6000 and len(list_cds)!=0 and len(list_3utr) <= 1500 and len(list_3utr) != 0 :\n",
    "        f3.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2=open('D:/unilm/data/mrna.txt','r')\n",
    "for lines in f2.readlines():\n",
    "    list_5utr=[]\n",
    "    list_cds=[]\n",
    "    list_3utr=[]\n",
    "    y=0\n",
    "    for strings in lines:\n",
    "        if strings.isupper():\n",
    "            list_cds.append(strings)\n",
    "            y=y+1\n",
    "            continue\n",
    "        if y != 0 :\n",
    "            if strings.islower():\n",
    "                list_3utr.append(strings)\n",
    "                continue\n",
    "        list_5utr.append(strings)\n",
    "    if len(list_5utr) <= 1500 and len(list_5utr) >1 and len(list_cds) <= 6000 and len(list_cds)!=0 and len(list_3utr) <= 1500 and len(list_3utr) != 0 :   \n",
    "        print(len(list_5utr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2.close()\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220 38313 970\n"
     ]
    }
   ],
   "source": [
    "#检查筛选后序列数量\n",
    "f3=open('D:/unilm/data/mrna_final.txt','r')\n",
    "a=0\n",
    "b=0\n",
    "c=0\n",
    "for lines in f3.readlines():\n",
    "    list_5utr=[]\n",
    "    list_cds=[]\n",
    "    list_3utr=[]\n",
    "    y=0\n",
    "    for strings in lines:\n",
    "        if strings.isupper():\n",
    "            list_cds.append(strings)\n",
    "            y=y+1\n",
    "            continue\n",
    "        if y != 0 :\n",
    "            if strings.islower():\n",
    "                list_3utr.append(strings)\n",
    "                continue\n",
    "        list_5utr.append(strings)            \n",
    "    if len(list_5utr) <= 20 :\n",
    "        a=a+1\n",
    "    if len(list_cds) <= 6000 and len(list_cds) !=0 :\n",
    "        b=b+1\n",
    "    if len(list_3utr) <= 50 :\n",
    "        c=c+1\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照8：1：1划分数据集\n",
    "import numpy as np\n",
    "data=open('D:/unilm/data/mrna_final.txt','r').readlines()\n",
    "np.random.shuffle(data)\n",
    "train_size=int(0.8*len(data))\n",
    "valid_size=int(0.1*len(data))\n",
    "train_data=data[:train_size]\n",
    "valid_data=data[train_size:train_size+valid_size]\n",
    "test_data =data[train_size+valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4=open('D:/unilm/data/train.txt','w')\n",
    "f5=open('D:/unilm/data/valid.txt','w')\n",
    "f6=open('D:/unilm/data/test.txt','w')\n",
    "for lines in train_data:\n",
    "    f4.write(lines)\n",
    "for lines in valid_data:\n",
    "    f5.write(lines)\n",
    "for lines in test_data:\n",
    "    f6.write(lines)\n",
    "f4.close()\n",
    "f5.close()\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分别生成CDS+5utr,CDS+3utr的标准输入格式，CDS为真值，utr为预测值，后续进行机器翻译任务\n",
    "f3=open('D:/unilm/data/mrna_final.txt','r')\n",
    "f4=open('D:/unilm/data/mrna_5utr.txt','w')\n",
    "f5=open('D:/unilm/data/mrna_3utr.txt','w')\n",
    "for lines in f3.readlines():\n",
    "    lines= lines.strip(' ')\n",
    "    list_5utr=[]\n",
    "    list_cds=[]\n",
    "    list_3utr=[]\n",
    "    y=0\n",
    "    str_5utr=''\n",
    "    str_3utr=''\n",
    "    for strings in lines:\n",
    "        if strings.isupper():\n",
    "            list_cds.append(strings)\n",
    "            y=y+1\n",
    "            continue\n",
    "        if y != 0 :\n",
    "            if strings.islower():\n",
    "                list_3utr.append(strings)\n",
    "                continue\n",
    "        list_5utr.append(strings)\n",
    "    str_5utr=''.join(list_cds)+'\\t'+''.join(list_5utr).upper()\n",
    "    str_3utr=''.join(list_cds)+'\\t'+''.join(list_3utr).upper()\n",
    "    f4.write(str_5utr)\n",
    "    f5.write(str_3utr+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分别生成CDS，5utr，3utr的标准输入格式，CDS为真值，utr为预测值，后续进行机器翻译任务，CDS为src_file,5utr和3utr为tgt_file\n",
    "f3=open('D:/unilm/data/valid.txt','r')\n",
    "f4=open('D:/unilm/data/val_cds.txt','w')\n",
    "f5=open('D:/unilm/data/val_3utr.txt','w')\n",
    "f6=open('D:/unilm/data/val_5utr.txt','w')\n",
    "for lines in f3.readlines():\n",
    "    lines= lines.strip(' ')\n",
    "    list_5utr=[]\n",
    "    list_cds=[]\n",
    "    list_3utr=[]\n",
    "    y=0\n",
    "    str_5utr=''\n",
    "    str_3utr=''\n",
    "    for strings in lines:\n",
    "        if strings.isupper():\n",
    "            list_cds.append(strings)\n",
    "            y=y+1\n",
    "            continue\n",
    "        if y != 0 :\n",
    "            if strings.islower():\n",
    "                list_3utr.append(strings)\n",
    "                continue\n",
    "        list_5utr.append(strings)\n",
    "    f4.write(''.join(list_cds).upper()+'\\n')\n",
    "    f5.write(''.join(list_3utr).upper()+'\\n')\n",
    "    f6.write(''.join(list_5utr).upper())\n",
    "f3.close()\n",
    "f4.close()\n",
    "f5.close()\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将序列作为句子，单个密码子作为词\n",
    "f4=open('D:/unilm/data/5utr.txt','r')\n",
    "f5=open('D:/unilm/data/5utr_word.txt','w')\n",
    "for line in f4:\n",
    "    line=line.strip('\\n')\n",
    "    for i in range(len(line)):\n",
    "        f5.writelines(line[i]+'\\n')\n",
    "        if i == (len(line)-1):\n",
    "            f5.write('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将txt格式转换为fasta\n",
    "f1=open('D:/unilm/data/3utr.txt','r')\n",
    "f2=open('D:/unilm/data/3utr.fasta','w')\n",
    "for lines in f1.readlines():\n",
    "    f2.write('>'+'\\n')\n",
    "    f2.write(lines)\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({Seq('TTT'): 859596, Seq('AAA'): 737896, Seq('CTG'): 587182, Seq('TGT'): 527850, Seq('CCT'): 526699, Seq('TCT'): 506366, Seq('CAG'): 502091, Seq('CTT'): 496322, Seq('CCC'): 493989, Seq('AAT'): 485193, Seq('ATT'): 484817, Seq('CCA'): 467598, Seq('TGG'): 466861, Seq('TTC'): 454583, Seq('TTG'): 446538, Seq('AGA'): 438484, Seq('CTC'): 435812, Seq('TAA'): 433286, Seq('TTA'): 423500, Seq('TGA'): 422474, Seq('TCC'): 419699, Seq('AGG'): 417271, Seq('GAA'): 415631, Seq('GGG'): 415257, Seq('AAG'): 408566, Seq('TCA'): 405400, Seq('ACA'): 397448, Seq('GAG'): 387945, Seq('GGA'): 387232, Seq('ATG'): 387180, Seq('TGC'): 383785, Seq('TAT'): 383546, Seq('GTG'): 379613, Seq('GCC'): 377866, Seq('ATA'): 373313, Seq('CAT'): 371063, Seq('GCT'): 366884, Seq('CAC'): 366359, Seq('ACT'): 363073, Seq('CAA'): 354551, Seq('AGC'): 348265, Seq('GTT'): 342602, Seq('AGT'): 333971, Seq('GGC'): 330179, Seq('GCA'): 328440, Seq('ACC'): 299512, Seq('AAC'): 299251, Seq('GAT'): 264827, Seq('GGT'): 264255, Seq('ATC'): 261084, Seq('CTA'): 245228, Seq('GTC'): 243520, Seq('GTA'): 243210, Seq('GAC'): 237689, Seq('TAG'): 236560, Seq('TAC'): 227940, Seq('CCG'): 104781, Seq('CGG'): 93974, Seq('CGC'): 81531, Seq('CGT'): 81210, Seq('GCG'): 73834, Seq('ACG'): 73182, Seq('TCG'): 63627, Seq('CGA'): 59375, Seq('ACN'): 2, Seq('CNA'): 2, Seq('NAA'): 2, Seq('AAN'): 2, Seq('ANN'): 2, Seq('NNT'): 2, Seq('NTG'): 2, Seq('TCN'): 2, Seq('CNC'): 2, Seq('NCT'): 2})\n"
     ]
    }
   ],
   "source": [
    "#计算K-mers,输出所有子片段的频率\n",
    "from Bio import SeqIO\n",
    "def build_kmers(seq, k_size):\n",
    "    \"\"\"a function to calculate kmers from seq\"\"\"\n",
    "    kmers = []  # k-mer存储在列表中\n",
    "    n_kmers = len(seq) - k_size + 1\n",
    "    \n",
    "    for i in range(n_kmers):\n",
    "        kmer = seq[i:i + k_size]\n",
    "        kmers.append(kmer)\n",
    "        \n",
    "    return kmers\n",
    "\n",
    "from collections import Counter\n",
    "def summary_kmers(kmers):\n",
    "    \"\"\"a function to summarize the kmers\"\"\"\n",
    "    kmers_stat = Counter(kmers)\n",
    "    return kmers_stat\n",
    "sum=Counter()\n",
    "for seq_record in SeqIO.parse('3utr.fasta','fasta'):\n",
    "    a=summary_kmers(build_kmers(seq_record.seq.upper(),3))\n",
    "    sum=sum+a\n",
    "print(sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3mers=dict(sum)\n",
    "list1=[]\n",
    "list2=[]\n",
    "mersdict={}\n",
    "for keys in _3mers.keys():\n",
    "    list1.append(keys)\n",
    "    list2.append(_3mers[keys])\n",
    "mersdict['seq']=list1\n",
    "mersdict['num']=list2\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(mersdict)\n",
    "df.to_csv('D:/unilm/data/3mers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('D:/unilm/data/k-mers/5utr/8mers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort=df.sort_values(by=['num'],ascending=[False])\n",
    "b=df_sort.reset_index(drop=True)\n",
    "a=b.seq.iloc[:65536]\n",
    "result=a.to_list()\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open('D:/unilm/data/k-mers/3utr/8mers_all.txt','w')\n",
    "for i in result:\n",
    "    f1.write(str(i)+'\\n')\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将txt格式转换为json格式\n",
    "import json\n",
    "f1=open('D:/unilm/data/test/test_cds.txt','r').readlines()\n",
    "f2=open('D:/unilm/data/test/test_5utr.txt','r').readlines()\n",
    "dict1={}\n",
    "with open('D:/unilm/data/test/test.json','a+') as json_file:\n",
    "    for i in range(len(f1)):\n",
    "        dict1['src_txt']=f1[i].strip()\n",
    "        dict1['tgt_txt']=f2[i].strip()    \n",
    "        json_list=json.dumps(dict1)\n",
    "        json_file.write(json_list+'\\n')\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12561 11634 4007 1458 612 377 30650\n"
     ]
    }
   ],
   "source": [
    "#序列长度分布分析\n",
    "l_1000=0\n",
    "l_2000=0\n",
    "l_3000=0\n",
    "l_4000=0\n",
    "l_5000=0\n",
    "l_6000=0\n",
    "with open('D:/unilm/data/train/train_cds.txt','r') as f1:\n",
    "    data=f1.readlines()\n",
    "    for line in data:\n",
    "        if len(line) <= 1000 :\n",
    "            l_1000+=1\n",
    "        if len(line) > 1000 and len(line) <= 2000 :\n",
    "            l_2000+=1\n",
    "        if len(line) > 2000 and len(line) <= 3000 :\n",
    "            l_3000+=1\n",
    "        if len(line) > 3000 and len(line) <= 4000 :\n",
    "            l_4000+=1\n",
    "        if len(line) > 4000 and len(line) <= 5000 :\n",
    "            l_5000+=1\n",
    "        if len(line) > 5000 and len(line) <= 6000 :\n",
    "            l_6000+=1\n",
    "print(l_1000,l_2000,l_3000,l_4000,l_5000,l_6000,len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/bert_seq2seq/result/predict.txt','r') as f1:\n",
    "    with open('D:/bert_seq2seq/result/predict1.txt','w') as f2:\n",
    "        lines=f1.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip(' ')\n",
    "            f2.write(line)\n",
    "    f2.close()\n",
    "f1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.35176167613548576,\n",
       "  'p': 0.3643536382948428,\n",
       "  'f': 0.34684627583221034},\n",
       " 'rouge-2': {'r': 0.3360165828298533,\n",
       "  'p': 0.347034913005982,\n",
       "  'f': 0.3324425240183405},\n",
       " 'rouge-l': {'r': 0.35173481903555864,\n",
       "  'p': 0.3643192680878365,\n",
       "  'f': 0.34681661087545856}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import FilesRouge\n",
    "from rouge import Rouge\n",
    "def rouge_score(pre_list,true_list):\n",
    "    rouge = Rouge()\n",
    "    for i in range(len(pre_list)):\n",
    "        if pre_list[i]=='' or pre_list==' ':\n",
    "            pre_list[i]='#'\n",
    "    rouge_scores = rouge.get_scores(pre_list, true_list,avg=True)\n",
    "    return rouge_scores\n",
    "pre_list=open('D:/bert_seq2seq/result/bert_2048_5utr.txt','r').readlines()\n",
    "true_list=open('D:/bert_seq2seq/data/test/test_5utr_token_new.txt','r').readlines()\n",
    "rouge_score(pre_list,true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import FilesRouge\n",
    "\n",
    "rouger=FilesRouge()\n",
    "scores=rouger.get_scores('D:/bert_seq2seq/result/bert_2048_5utr.txt','D:/bert_seq2seq/data/test/test_5utr_token_new.txt',avg=True)\n",
    "scores\n",
    "# from rouge import Rouge \n",
    "\n",
    "# hypothesis = \"ACCCGCA AATGCTGC TGCCCCAG CTCTACA CTGCGCC CTGGTGCT GGCTGACC ACCCCCTG CCCTCCTG CCGGACC CTGGGGCC TCCCACCC CAGCCTCC CTGAGGCC CATACTC CACGGAG AGGAGCCC CATGCCCA GCCTGGCT GAGCCCG AGATTCG CTCCTCCC CCTCATG CCAACCCC ACACAGG TCCCGGC CTTTTAA TGTTCTT TGAATAAA CACTTTA TTTTCTA ATAAAATA AAAAAGGA AACCTTGACACCA AAAAATAA AAGACTC CTACGAA GAACTGT TTTTGTTT TCCTCTTC CTTTTGA GAAGACA CTATGAA TTAAATT CTACAGCT TTTTTTTG ATATATG GAAATTT GTAGAAC AGAAATAT TTTAGTT AAAGTGT GACTTTC AGAAAGG GAAAATCA GGGCACAG CCTTGGT CTGTGTT CCCCAAA TATTCAC ACTTTAA AGAATTC TTCAACC CCCCAAGG GACAGTT ATGGTCC TTTGATT CTCTGCTG TGGCAGT AGGTGTG CCTCATG CCCTTCCA GTGCAAT GCAAGCC CTCCAGCC TCACCCC AGAGAGGA TCACTGA TGTCAGC AGCAGCCT GAGGCTGA ATCCAGG TTGAAAGA AGAATAA CTTGAAAA AATATATT TCCACAC ACAGAAT TTTGTTTT TCTTCCA AGTTGGT TAAGACA TATATTTT GTTTCTT TCTTCCA AGTTGGT TAAGACA TATATTTT GTTTCTT TCTTCCA AGTTGGT TAAGACA TATATTTT GTTTCTT TCTTCCA AGTTGGT TAAGACA TATATTTT GTTTCTT CCAAGAC TCCAGCCC TGATTGC GCAAAAC TGAAAGG CATGTGA AGGGAAGG AAGAGGAA GAGTGCA AAACATT GAAGAGAG AGCTGAG TGAGCTGA AGAGTGAG GATATGA GTAGCCC CAACCCA AACCTGGA GATGGGGA GAAACCT ACAGAAT ACTAGCC AGAGCTCC TCCTTGT CTTGGCA GCCTACT AGGGACCT GGGGAAGC AAAAACG AAAGCTGG GCAACAT GCCTGCT TTAGAAT GTTTTCC TTCTACT TACACAT CTTCCACA GGTCTCA GAATCTT TCCTTCCT CTCATCCT TTTCTCCT ATCTTCA TATCTAT CAGAGTA TCCACTG TTTATTC AACAACT ACTACTT GATGGTC AGACACA AACAAACA GGTGGATG CTGTGGTG GGAACGT TGCTTCA TCAGGCG TTGCCTC CGGTGTG GAGTTTG GGGCTTT AGGAAAGC CTGGGTT GGGTGGAG CAGAACCA TCTTGGAG AAGATGAC AGTTCCC TGTCCTCC CGGAGAT GCCTGGGT GTGTTAG CAGAGGTG ACACGTG TCTGACA GAGACGG GAGCTCTG AGTGTCC ACGGGTG AAGAAGTG AGTGTCC ACGGGTG AAGAAGTG AGTATGT TTCACCTG GACATTA AGGTGAT GTTTGAG CTGCTGTT AAGGAAT TTCTTGCT TATAGAG GCAAACC ACAGTAT CATTTTA ACTCTAG AATTGGG CTTGTAC AGAAGGAT AAAACCC AGGAAAAT GGATATT TCTATTC AGATTTA TTTATGC CTCTTTT TAATCCC CTTTAAT GATGCAG TGGTTTT TATCTGA TCAGGAA CTTGTCA TGATTTC CTTTCTT AGACTTC ATAGGAG ATAGTGC TTTAAAAA AAAAAAAA ACTTCTA TTATTTG TTTAGTA TGTTGTA AGTAGAT CATTTTA AAAAACTG AATCTAT ATTATGT TTAACTT CAGAAGGC ATCATTT ATAAGAC AGTATGG CAGTTAA TTATAAAA TTATTTTG ATGAATT ATGATAC AATCTAC ATAATAAA GAATCCT TTTGATT A CCAGGGCC CCTGACCT CCCCGCTG TGGGGGT TGGGGCT TCAGGCAG CAGACTG ACCATCT CCCAGACC GCCAGTGA CTGGGGGA GGACCTGC TCTGCCCT CTCCCCAC CCCTTCCA ATGAGCT CCTTGTT TTTGCCAA AGTTTCT AGGGGTG CCTCTGTG TTCATCC CCTTCCTG ATCTAAC CGGCTCC CTCGCCA GTCCCGG GGGCCTGC CCTGCTCC CACCAGGA GAGAGGG CAAAGGG ATGAGCC TGGGTTT GGACTCT AAAATCT CAGCACTG CCCCATGG GTCCTAG ACTTCCC AGGGCAAG AGGAAGAC CCTGCCA TTCCACA GCCCCTTC CTCTGCCA GGTGCTT GGCTCTC TGAGAGC AAACAGGA ACACTAG AGACCAA AAAGGGG ACAAAGGA GAAGGGC TGAGCCCA CCTTCTT GCTCCTA AGGCTTTG GGTGGCTC ACGCCTG TAATCCC AGCACTTT GGGAGGCC GAGGCAGG TGGATCA CCTGAGGT CAGGAGTT TGGGACCA GCCTGGCC AACATGG TGAAACC CCATCTCT ACTAAAAA TACAAAAA ATTAGCC GGGTGTGG TGGCGCG TGCCTAT AATCCCAG CTACTCG GGAGGCTG AGGCAGGA GAATCGC TTGAACC CGGGAGG TGGAGGT TGCGGTG AGCCAAGA TCGCACC ATTGCAC TCCAGCCT GGGCAAC AAGAGCG AAACTCT GTCTCAAA ATAAATAA ATAAATAA ATAAATAA AAAATAAA AGACAGAA AGCAAGG GGTGCCT AAATCTA GACTTGG GGTCCAC ACCGGGC AGCGGGG TTGCAAC CCAGCACC TGGTAGG CTCCATTT CTTCCCA AGCCCGA GCAGAGGG TCATGCG GGCCCCAC AGGAGAAG CGGCCAG GGCCCGC GGGGGGC ACCACCTG TGGACAGC CCTCCTGT CCCCAAGC TTTCAGG CAGGCAC TGAAACG CGCATGC CCAATAA ACTGACC CCACACT CACCCCG G C CGGCTGG GGCTGCAG AGTCTCT AGGGAAG TCGCGGC CACTGCCT GTGTGAC GGATGTG ACCCCGC TGGGCCTG AAGCTGGG CCCTCAC TGGCCTG TCCCTGCT GCAGCGCC AGGACCCC CGGAGGT AGAGGCG AGAGTGG AGGCTCT TCTTCTGC CCCGTCT CCCCTCA AAGATGAG AAACATGT TCAGAAGG AAACGGT GTCTCTC GGCTGTGG CTCTGAG TGCAAAT TGCATGG GCGGAAA GGCGGGGG TGGCTGCT CTTCCTGG CAGGCCTG GGCCATCA GCGAACT GGGCCCCG TGAGGAGG GCGGGAG TGTGGAGG AGGGTGGG CCTCTCA CCCAGGCT TTCTCGG CCCCTCTC CTCAGCTT GCAGAGCT GGCCAGCC CCCTCCTT AGGGGGT GGGCGAGG AGCCTCTG GGCAGAC CCAAGAAC CATGGGG ACTGGGG TGGGTTG GTGGCAC CAATGGC AGCCCTCC CCGCCCC TCTCCTTC AAGGAGGG TTCCCGC AGCTGGGG GGTGTGC GGAGGCGC ATGGCCT CCCGCCA CGGGGCCG TGCTGTGT TTATGGC TGGCAGAG GCAGCCAG CGGGTGG GGGATTC TGCTGCTC GCTCACC TGCCTGGC TCGCTGG TCTCTCG AATTTTC TTCCCTCT GAAATCC TATTTAA GAACTTT TGGAAGCT TAGCCAT TTTTACT TATTAAAA TAAAAGAA GCCTTTT TACACAA GCTGTCA CGACGCT CCCTCTGC CAGCTGGT CCCGGGA ATTCTGT GAACCAG GCTGCTGT CTCCTCCC CAGAAAGA GTCCTTA CCTTGGAG AGGGTCC TGGAGAGA ATTTCCT CTTCCCCA GCTAAAT ACCCTGCC TGCAACT GAAGCAGA CCCGGGG GTGTCCT CCCTGCCC TCTGCCCA GAGGCCAC CTCCACT CCTACAA AATCAAA GTATTGT CCAGACA AGAGTCA CTGGCCCC TGCTCCAG CTTCTGGG TATCCAG AGAGCAC TGCACTT CCCCAAA ACGGAAG GGGCCCCT GGGCAGTG GGTTTTG GGCAAAT TCCCTTTC TTTGCAT CCACAAT GTGGGGT CGGAGCT TGGGGGCA GGTCCTGG GAGTGGG AAGCCTC TTCCTTG TGTCTTT CGCTCCA CTTTTAG CTCATCG CACCAAT ATTGCAG ACTTGGAA GGAAGCA TAAGCTT CCCATTT CACAAAG GGGAAAC TGAGGTG CGGGTGC GCGGGCC TGGGGAC GGCCGTC CCATGGCT TCCATCT GAGCCACC TCGGGAC CCCAGCAC TCCTGGC GCCCTCT TCTCATA GCTTGGC CTATGACA GGTCACC GTGTGTA AATCTTT CCCAATA AAGTGTT GCACAAA G CGACCCT CCCTGCAG GGCTGGGC TTTTGCA TGGCAAT GGATGGG ACATTAA AGGGACA TGTAACA AGCACAC CGGCCTG CTGTTCT GTCCTTC CATCCCT CTTTTGG GCTCTTCT GGAGGGAA GTAACAT TTACTGA GCACCTG TTGTATG TCACATG CCTTATG AATAGAA TCTTAAC TCCTAGA GCAACTC TGTGGGG TGGGGAGG AGCAGATC CAAGTTT TGCGGGG TCTAAAG CTGTGTGT GTTGAGG GGGATAC TCTGTTT ATGAAAAA GAATAAAA AACACAA CCACGAA TTTCCAT TAAAATG GCTTTTA AAATGTC AAGTGAA TTCTAGT TATCTAT TCTGAGA TGCCTTG CTGTTCA GAATAAA TTTAAATT GAATAAA TTTAAATT TTGTAAT GAATAAA TTTAAATT GAATAAA TTTAAATT GAATAAA TTTAAATT GAATAAA TTTAAATT GAATAAA TTTAAATT GAATAAA TTTAAATT TCATTTTT CCCAGGCT GGAGTGC AATGGCA CGATCTC GGCTCAC TGCAACC TCTGCCTC CTGGGTT CAAGCAA TTCTCCTG CCTCAGCC TCCCAAAG TGCTGGGA TTACAGG CGTGAGC CACTGTGC TTTTGCTT ATGTACT TTATTTTT GAATATT GTACAGT TAATTTC ATTCTCC TGCCTCAG CCTCCCAA AGTGCTGG GATTACA GGCACGT GCCATCA CGCCAGG CTGGAGTG CAGTGGC GCGGTCT CGGCTCA CTGCAAG CTCTGCCT CCCAGGT TCAAGCG ATTCTCC TGCCTCAG CCTCCCG AGTAGCT GGGACTA CAGGCACC CGCCACC ATGCCCG GCTAATT TTTTGTAT TTTTAGT AGAGACG GGGTTTC ACTGTGT GTATTTTT AGTAGAG ACGGGGT TTCACCAT GTTGGCC AGGCTGGT CTCGAAC TCTTGAC CTCAGGT GATCTGC CAGCCTCC CAAGTAG CTGGGATT ACAGGCA CGTGCCA CTGCACTC CAGCCTGG GCAACAA GAGCGAA GATGGCAG TAACTGT TAAATAA TTTTAGT AGAGACG GGGTTTC ACCATGT TGCCCAGG CTGGAGTG CAGTGGC GCGGTCT CGGCTCA CTGCAAG CTCTGCCT CCCAGGT TCAAGTG ATTCTCC TGCCTCAG CCTCCCAA AGTGCTGG GATTACA GGCGTGA GCCACTG TGCCTGGC TTTTAGT AGAGACG GGGTTTC ACTGTGT TGAACCA AGAGCCTG CGGGACA CAGAACAG TGAACAG GGAGGACT CTGATGAA CAAGACCC TCAGGAGG TGACATA CGCACAG TTGGATC ACTGCAT TTTCACA CAGAGAAA AATCACT GGCCCTT CTCAGAGG AGCAAGAG ACCCTCA ACAGATA CCAGCGT GTGTATA GAACTTCC AAATGCTG AGCCCAGA GCGTTGT CTCCTGCC CATGAGC ACCACAGT CAGGCCTT GATGGGA TCTTCTA GGGAGACA ACAGCCCT GTCTCAAA CCCAGCTT GCCAGCTC TAATGTA CCAGCAGC TGGAATCT GAAGGCG TGAGTCT CCATCTT AGAGCAT CACTCTT CCTCACAC CACAAAT CTGGTGCC TGTCTCT TGCTTAC CAATGTC TAAGGTC CCCACTGC CTGCTGCA GAGAAAAC ACACTCC TTTGCTT AGCCCACA ATTCTCT ATTTCAC TTGACCC CTGCCCAC CTCTCCAA CCTAACT GGCTTAC TTCCTAG TCTACTT GAGGCTGC AATCACA CTGAGGAA CTCACAA TTCCAAAC ATACAAG AGGCTCT CTCTTAA CACGGCA CTTAGAC ACGTGCTG TTCCACCT TCCCTCG TGCTGTTC CACCTTT CCTCAGAC TATTTTTC AGCCTTCT GGCATCAG CAAACCT TATAAAA TTTTTTTG ATTTCAG TGTAGTT CTCTCCTC TTCAAATA AACATGT CTGCCTTC A GCCCTCA CTCCAAAA AAACAAAA AACAGGG TAAGAAAA TTACTTG GGTGGGT AGACTTA GGAACGC TCTACTT CGTAAAA GCATTAT ACAAAGT CACGGGA GAAAAATA TGGGACA TTTCTTG ATTGTAC TTAATCT AATTTGA TTAGATT ATAGAGT CCTAAGT ATTAATT ATTGCCA CCATCAA ACTCATT GAGTCCT ATGGTTC ACATCTT GTTTCCT ATAGAAA TGTCCTG TATTCTG GGATCAA TTTCCAAA TGCTTTA CTTTTTT ATTTCTG CAAGTTCA AATTAAT GTATTAT AGAAGTT ATGAGTT AAATAAAG ATTGGAA TATCACC T TGAGTCA TAATATT ATACAAA TTCAGAG TGTTATT AAAGAGG TATTGAA ATATTT\"\n",
    "\n",
    "# reference = \"ACCCGCA AATGCTGC TGCCCCAG CTCTACA CTGCGCC CTGGTGCT GGCTGACC ACCCCCTG CCCTCCTG CCGGACC CTGGGGCC TCCCACCC CAGCCTCC CTGAGGCC CATACTC CACGGAG AGGAGCCC CATGCCCA GCCTGGCT GAGCCCG AGATTCG CTCCTCCC CCTCATG CCAACCCC ACACAGG TCCCGGC CTTTTAA TGTTCTT TGAATAAA CACTTTA TTTTCTA ATAAAATA AAAAAGGA AACCTT GACACCA AAAAATAA AAGACTC CTACGAA GAACTGT TTTTGTTT TCCTCTTC CTTTTGA GAAGACA CTATGAA TTAAATT CTACAGCT TTTTTTTG ATATATG GAAATTT GTAGAAC AGAAATAT TTTAGTT AAAGTGT GACTTTC AGAAAGG GAAAATCA GGGCACAG CCTTGGT CTGTGTT CCCCAAA TATTCAC ACTTTAA AGAATTC TTCAACC CCCCAAGG GACAGTT ATGGTCC TTTGATT CTCTGCTG TGGCAGT AGGTGTG CCTCATG CCCTTCCA GTGCAAT GCAAGCC CTCCAGCC TCACCCC AGAGAGGA TCACTGA TGTCAGC AGCAGCCT GAGGCTGA ATCCAGG TTGAAAGA AGAATAA CTTGAAAA AATATATT TCCACAC ACAGAAT TTTGTTTT TCTTCCA AGTTGGT TAAGACA TATATTTT GTTTCTT TTTTTTTT TTTTTTTT GAGACGG AGTCTCG CTCTGTA GCCCAGGC TGAAGCG CAGTGGTG TGAGCTC GGCTTAC TGCAAGC TCCACCTC CCGGGTT CACGCCA TTCTCCT ACCTCAGC CTCCCGA GTAGCTG GGACTAT AGGCACC CGCCACC ATGCCCG GCTAATT TTTGTAT CTTTAGT AGAGACG GGGTTTC ACTGTGT TAGCTAG GATGGTC TTGATCT CCTGACCT TGTGATC CGCCCAC CTTGGCCT CCCAAGGT ACTGCGA TTACAGG CATGAGC TACCATG CCCGGCC ACAAGAC ATAGATT TTCTATA TGCACAT CAAGGGA GGTGCTGG TTTAGGT TGCTATA GGACAGAG CTATCCT GTATTCC AGTTGGT TTTTGTA GAGAAACA ATTAGAC TTCTCTA GATAGAG CCCTGAT TTTTCTCT CACGCTT TCAGTTT TTTAAAAG CACTAAT GATATTT CCTGTTT TCTCATA AGAAAAAG TCAATAC TATGCCT TACAAAG AGACCTT TCCTTCT AATATAG AATTTTAT TTGAAAG TGAGTAC ATGTTTA TAACTAG AGAATAAA AGGAGAAT TTTTGAA CAGAGGTG ACACGTG TCTGACA GAGACGG GAGCTCTG AGTGTCC ACGGGTG AAGAAGTG AGTGTCC ACGGGTG AAGAAGTG AGTATGT TTCACCTG GACATTA AGGTGAT GTTTGAG CTGCTGTT AAGGAAT TTCTTGCT TATAGAG GCAAACC ACAGTAT CATTTTA ACTCTAG AATTGGG CTTGTAC AGAAGGAT AAAACCC AGGAAAAT GGATATT TCTATTC AGATTTA TTTATGC CTCTTTT TAATCCC CTTTAAT GATGCAG TGGTTTT TATCTGA TCAGGAA CTTGTCA TGATTTC CTTTCTT AGACTTC ATAGGAG ATAGTGC TTTAAAAA AAAAAAAA ACTTCTA TTATTTG TTTAGTA TGTTGTA AGTAGAT CATTTTA AAAAACTG AATCTAT ATTATGT TTAACTT CAGAAGGC ATCATTT ATAAGAC AGTATGG CAGTTAA TTATAAAA TTATTTTG ATGAATT ATGATAC AATCTAC ATAATAAA GAATCCT TTTGATT A GCAGCTTC AAGAGCAA CTTCTCCA CATGTTG GGTGTCC ATCCTGGG GCAGGGAA GGACAGAG TGTTGGA TGGCTGGG ACGGGGC CTTGCTC TTGTCGG CCAGCCCA CTCCCCAG CCAGAGAG GGCTTGA CCAAATC AAATTGA GGTGGTGA CTTTTGT TGGAAAAT TGGGCTGG GATCACG TCCTGTT TTGTAAT AAAAGCTG AAAAGTC TGCA CGGACGC GTGGCCCT GAGTTGG GGGAGCG ACCCTTC CCCCAGCC CCGCCCC TCAGGACA CCCAGAAC CCCACCCC TCGTCCT CTCGGCC TTCTGTA ATAGTTT TGAGATG TCTGTCC CTCCTCCC TGGAGCTC CAGAGACC CACCCCTC TCCAGGT TATCCCA GAAATGA CCCAACT CTCTCAC TTTTCCCT CTCCCCT TTGAATA AAGTCGC CAGCTAG AGCACGT G A GGGGCTT GGCATGG CCGCAGT GGGGGCTG GGGACTGG CGCAGCCC CAGGCGC CTCCAAGG GAAGCAGT GAGGAAAG ATGAGGC ATCGTGC CTCACAT CCGCTCC ACATGGTG CAAGAGCC TCTAGCG GCTTCCAG TTCCCCG CTCCTGAC TCCTGACC TCCAGGA TGTCTCC CGGTTTC TTCTTTC AAAATTT CCTCTCCA TCTGCTGG CACCTGAG GAGAGTGA GCAGCCTG GACCACA AGCCCAG TGGTCAC CCCTGTG TGCGCCC GCCCCAGC CCAGGAGT AGTCTTA CCTCTGAG GAACTTT CTAGATG CAAAGTG TGTATGT GTGTGTGT GTGTGTGT GTGTGTGT GTTTGTG TGTATTTT GTAATAT GTGAGGG AAATCTA CCTTCGT TCATGTA TAAATAAA GCTCCTC GTGGCTCC C GCTGTCA CGACGCT CCCTCTGC CAGCTGGT CCCGGGA ATTCTGT GAACCAG GCTGCTGT CTCCTCCC CAGAAAGA GTCCTTA CCTTGGAG AGGGTCC TGGAGAGA ATTTCCT CTTCCCCA GCTAAAT ACCCTGCC TGCAACT GAAGCAGA CCCGGGG GTGTCCT CCCTGCCC TCTGCCCA GAGGCCAC CTCCACT CCTACAA AATCAAA GTATTGT CCAGACA AGAGTCA CTGGCCCC TGCTCCAG CTTCTGGG TATCCAG AGAGCAC TGCACTT CCCCAAA ACGGAAG GGGCCCCT GGGCAGTG GGTTTTG GGCAAAT TCCCTTTC TTTGCAT CCACAAT GTGGGGT CGGAGCT TGGGGGCA GGTCCTGG GAGTGGG AAGCCTC TTCCTTG TGTCTTT CGCTCCA CTTTTAG CTCATCG CACCAAT ATTGCAG ACTTGGAA GGAAGCA TAAGCTT CCCATTT CACAAAG GGGAAAC TGAGGTG CGGGTGC GCGGGCC TGGGGAC GGCCGTC CCATGGCT TCCATCT GAGCCACC TCGGGAC CCCAGCGC TCCTGGC GCCCTCT TCTCATC GCTTGGC CTATGACA GGTCACC GTGTGTA AATCTTT CCCAATA AAGTGTT GCACAAA G AAAACTT CCAGCACA TTGGGGT GGAGGGCC TGCCTCA CTGGGTCC CAGCTCCC CGCTCCT GTTAGCC CCATGGGG CTGCCGG GCTGGCCG CCAGTTT CTGTTGC TGCCAAA GTAATGT GGCTCTC TGCTGCCA CCCTGTGC TGCTGAGG TGCGTAG CTGCACAG CTGGGGGC TGGGGCG TCCCTCTC CTCTCTCC CCAGTCT CTAGGGC TGCCTGA CTGGAGGC CTTCCAAG GGGGTTT CAGTCTG GACTTAT ACAGGGAG GCCAGAAG GGCTCCA TGCACTG GAATGCG GGGACTC TGCAGGTG GATTACC CAGGCTCA GGGTTAA CAGCTAG CCTCCTA GTTGAGA CACACCT AGAGAAGG GTTTTTG GGAGCTGA ATAAACT CAGTCAC CTGGTTT CCCATCTC TAAGCCC CTTAACC TGCAGCT TCGTTTA ATGTAGC TCTTGCA TGGGAGT TTCTAGG ATGAAAC ACTCCTC CATGGGA TTTGAAC ATATGAA AGTTATT TGTAGGG GAAGAGT CCTGAGGG GCAACAC ACAAGAA CCAGGTCC CCTCAGCC CACAGCAC TGTCTTT TTGCTGA TCCACCCC CCTCTTA CCTTTTA TCAGGAT GTGGCCTG TTGGTCC TTCTGTT GCCATCA CAGAGACA CAGGCAT TTAAATA TTTAACT TATTTATT TAACAAA GTAGAAG GGAATCC ATTGCTA GCTTTTC TGTGTTGG TGTCTAA TATTTGG GTAGGGT GGGGGAT CCCCAACA ATCAGGT CCCCTGAG ATAGCTG GTCATTG GGCTGAT CATTGCCA GAATCTT CTTCTCCT GGGGTCT GGCCCCCC AAAATGC CTAACCC AGGACCT TGGAAATT CTACTCA TCCCAAA TGATAAT TCCAAATG CTGTTAC CCAAGGT TAGGGTG TTGAAGGA AGGTAGA GGGTGGGG CTTCAGG TCTCAAC GGCTTCCC TAACCAC CCCTCTTC TCTTGGC CCAGCCTG GTTCCCC CCACTTCC ACTCCCC TCTACTC TCTCTAG GACTGGG CTGATGAA GGCACTGC CCAAAAT TTCCCCT ACCCCCAA CTTTCCCC TACCCCC AACTTTC CCCACCAG CTCCACA ACCCTGT TTGGAGCT ACTGCAGG ACCAGAAG CACAAAG TGCGGTT TCCCAAG CCTTTGT CCATCTC AGCCCCCA GAGTATA TCTGTGCT TGGGGAA TCTCACA CAGAAACT CAGGAGCA CCCCCTGC CTGAGCT AAGGGAG GTCTTAT CTCTCAGG GGGGGTT TAAGTGC CGTTTGC AATAATG TCGTCTT ATTTATTT AGCGGGG TGAATAT TTTATAC TGTAAGT GAGCAAT CAGAGTA TAATGTT TATGGTG ACAAAAT TAAAGGC TTTCTTA TATGTTT A GTGCCTA AGTGTAT ACAGTGA GAGCATC TATAGAA GCCTAGA AGAATTC TGTTATG TTTAGAC TATGTCT TATCTTT AGACTAT TTCAGGC TTAATTTT CCTAACT TGTTCAG CACTAGT GCTTTAC CTCTCAT TTTTAATT GAACTGT TAGGAAT TGTGTGGG GAAAAAAA GTAAATA AATGTTC GCTTCCA A TGAACCA AGAGCCTG CGGGACA CAGAACAG TGAACAG GGAGGACT CTGATGAA CAAGACCC TCAGGAGG TGACATA CGCACAG TTGGATC ACTGCAT TTTCACA CAGAGAAA AATCACT GGCCCTT CTCAGAGG AGCAAGAG ACCCTCA ACAGATA CCAGCGT GTGTATA GAACTTCC AAATGCTG AGCCCAGA GCGTTGT CTCCTGCC CATGAGC ACCACAGT CAGGCCTT GATGGGA TCTTCTA GGGAGACA ACAGCCCT GTCTCAAA CCCAGCTT GCCAGCTC TAATGTA CCAGCAGC TGGAATCT GAAGGCG TGAGTCT CCATCTT AGAGCAT CACTCTT CCTCACAC CACAAAT CTGGTGCC TGTCTCT TGCTTAC CAATGTC TAAGGTC CCCACTGC CTGCTGCA GAGAAAAC ACACTCC TTTGCTT AGCCCACA ATTCTCT ATTTCAC TTGACCC CTGCCCAC CTCTCCAA CCTAACT GGCTTAC TTCCTAG TCTACTT GAGGCTGC AATCACA CTGAGGAA CTCACAA TTCCAAAC ATACAAG AGGCTCT CTCTTAA CACGGCA CTTAGAC ACGTGCTG TTCCACCT TCCCTCG TGCTGTTC CACCTTT CCTCAGAC TATTTTTC AGCCTTCT GGCATCAG CAAACCT TATAAAA TTTTTTTG ATTTCAG TGTAGTT CTCTCCTC TTCAAATA AACATGT CTGCCTTC A GGACCCA ATATTGG CCTGTTT GCAACAGC TAGAATT AAATTTTA CTTTTAA GTAA TGGTTAA GCTACCT TCATTAA GCAGCAT GACCGCT TCCTGAGC TCCTGCTG CCGCATT TAGGCCC TGTCAGCT GTGAGGC CACTGGTG CTGAGTC AGAGGGAA AAGCTCA GAACAGC CTTGAGC AGCGAAG AATAAAGC ATGACTC ATCTCGT CCTGCCCA CCCCTCAC ACTGGAC TATAAAT ACCCTCCC TGGGTCT GTGTGCTG TTATTCC AAAAGATG CGATGAA TACCCAG AACTAGG CTATTCA TGGGCTG TTGCCCAG TTCAAGC TCTATTG GGTCCTG AGGAAGAT TACTATT TTGGCTA CATTGTT TATCATT AAAACCAG CCCAGGGA TGTGTAA ACCTGCA TCTGGAGA ATAAGAC ATTTCTTT TTGGTTA AATGATA TTAGAGA AAAAAAAA ACTATCC AAGGCTGC TAACAAA TAATCTT CACTTTC AATTATA TCCAGCAA TAAGTTG TTCTCCAG AAAAGAAA GCTTGGA AACTTAC CCAGTTT GCCTTCCA TTTGGGA CATGACT GATGTGC TTCAGTC TTTGTAT AATAAATG CATCTTC GCCACTC T A \"\n",
    "\n",
    "# rouger = Rouge()\n",
    "# scores = rouger.get_scores(hypothesis, reference)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37687005464788204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=scores['rouge-1']\n",
    "b=(a['r']+a['p']+a['f'])/3\n",
    "b=(a['r']+a['p']+a['f'])/3\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          r         p         f\n",
      "0  0.376084  0.386528  0.367999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sc_l=[]\n",
    "sc_l.append(scores['rouge-1'])\n",
    "df=pd.DataFrame(sc_l)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20122\n",
      "Jaccard系数: 0.8547710740265297\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    # 计算两个集合的交集\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    \n",
    "    # 计算两个集合的并集\n",
    "    union = len(set1.union(set2))\n",
    "    \n",
    "    # 计算Jaccard系数\n",
    "    jaccard_coefficient = intersection / union\n",
    "    \n",
    "    return jaccard_coefficient\n",
    "\n",
    "# 从文本文件加载数据到集合(整个文件作片段分割)\n",
    "def load_text_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        # 将文本拆分为单词，并创建一个包含单词的集合\n",
    "        word_set = set(text.split())\n",
    "        return word_set\n",
    "\n",
    "# 读取两个文本文件\n",
    "document1 = load_text_file(\"D:/bert_seq2seq/result/bert_2048_3utr.txt\")\n",
    "document2 = load_text_file(\"D:/bert_seq2seq/data/test/test_3utr_token_new.txt\")\n",
    "print(len(document1))\n",
    "# 计算Jaccard系数\n",
    "\n",
    "jaccard_coefficient = jaccard_similarity(document1, document2)\n",
    "\n",
    "print(\"Jaccard系数:\", jaccard_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard系数: 0.31935731349997715\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    # 计算两个集合的交集\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    # 计算两个集合的并集\n",
    "    union = len(set1.union(set2))\n",
    "    # 计算Jaccard系数\n",
    "    jaccard_coefficient = intersection / union\n",
    "    return jaccard_coefficient\n",
    "\n",
    "def load_text_file(file):\n",
    "        # 将文本拆分为单词，并创建一个包含单词的集合\n",
    "        word_set=(set(file.split()))\n",
    "        return word_set\n",
    "f1=open(\"D:/bert_seq2seq/result/bert_2048_5utr.txt\",'r')\n",
    "f2=open(\"D:/bert_seq2seq/data/test/test_5utr_token_new.txt\",'r')\n",
    "document1=f1.readlines()\n",
    "document2=f2.readlines()\n",
    "jaccard_list=[]\n",
    "for i in range(len(document1)):\n",
    "    jaccard_coefficient = jaccard_similarity(load_text_file(document1[i]),load_text_file(document2[i]))\n",
    "    jaccard_list.append(jaccard_coefficient)\n",
    "\n",
    "print(\"Jaccard系数:\", sum(jaccard_list)/len(jaccard_list))\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5306\n"
     ]
    }
   ],
   "source": [
    "#计算预测得到的结果中各token出现的频率\n",
    "from collections import Counter\n",
    "def predict_token_count(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text=file.read()\n",
    "        word=text.split()\n",
    "        return Counter(word)\n",
    "txt_file=\"D:/bert_seq2seq/result/predict_5utr_128.txt\"\n",
    "token_count=predict_token_count(txt_file)\n",
    "print(len(token_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "# 两个核酸序列\n",
    "sequence1 = \"ACGTCGAAGCGCTGCTCCTGGAGCCGCGGAGGGTGCGGGTTTGGCTGCGGTGGTTTCTGTGGCGGTTGCTGTGGCGGAGTTTGGAGGTTGGAGAGAAATCCAGGTACTCACTAGACTGGTACCTTCTGCCACC\"\n",
    "sequence2 = \"ACACAAGCCTCCAACTTGGTGCTGACGGAAGTGGCCTCGTGGCTGTCTCCTGGCGCCTGCCCCGTCAGACAGGGGCCCCATCCCACTCGCTACCCTGTCCGATGGGGAAACTGAGGCACGGAGCTGGACAGTGACTCAGACACCAGGGCGAGAAAAATCATGGCTTTGAGGTCCTGTACCACAGCGTGAAGCAGGGGCCCATCTCCACCAAGGAGCTGGCGGACTTCATCCGGGAGAGGGCCACCATCGAGGAGACCTACTCGAAGGCG\"\n",
    "\n",
    "# 执行全局比对（Needleman-Wunsch算法）\n",
    "alignments = pairwise2.align.globalxx(sequence1, sequence2)\n",
    "\n",
    "# 输出比对结果\n",
    "for alignment in alignments:\n",
    "    print(format_alignment(*alignment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1,set2):\n",
    "    # 计算两个集合的交集\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    # 计算两个集合的并集\n",
    "    union = len(set1.union(set2))\n",
    "    # 计算Jaccard系数\n",
    "    jaccard_coefficient = intersection / union\n",
    "    return jaccard_coefficient\n",
    "def jaccard_set(seq):\n",
    "    return(set(seq.split()))\n",
    "def jaccard_score(pre_list,true_list):\n",
    "    jaccard_list=[]\n",
    "    for i in range(len(pre_list)):\n",
    "        jaccard_coefficient = jaccard_similarity(jaccard_set(pre_list[i]), jaccard_set(true_list[i]))\n",
    "        jaccard_list.append(jaccard_coefficient)\n",
    "    jaccard_scores=sum(jaccard_list)/len(jaccard_list)\n",
    "    return jaccard_scores\n",
    "\n",
    "pre_list=['A T G G A C',\n",
    "          ' ',\n",
    "          'C C G A T']\n",
    "true_list=['A G G C',\n",
    "           'A G',\n",
    "           'G A T G']\n",
    "try:\n",
    "    print(jaccard_score(pre_list,true_list))\n",
    "except:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACCCGCA', 'AAUGCUGC', 'UGCCCCAG', 'CUCUACA', 'CUGCGCC', 'CUGGUGCU', 'GGCUGACC', 'ACCCCCUG', 'CCCUCCUG', 'CCGGACC', 'CUGGGGCC', 'UCCCACCC', 'CAGCCUCC', 'CUGAGGCC', 'CAUACUC', 'CACGGAG', 'AGGAGCCC', 'CAUGCCCA', 'GCCUGGCU', 'GAGCCCG', 'AGAUUCG', 'CUCCUCCC', 'CCUCAUG', 'CCAACCCC', 'ACACAGG', 'UCCCGGC', 'CUUUUAA', 'UGUUCUU', 'UGAAUAAA', 'CACUUUA', 'UUUUCUA', 'AUAAAAUA', 'AAAAAGGA', 'AACCUU'] ['ACCCGCA', 'AAUGCUGC', 'UGCCCCAG', 'CUCUACA', 'CUGCGCC', 'CUGGUGCU', 'GGCUGACC', 'ACCCCCUG', 'CCCUCCUG', 'CCGGACC', 'CUGGGGCC', 'UCCCACCC', 'CAGCCUCC', 'CUGAGGCC', 'CAUACUC', 'CACGGAG', 'AGGAGCCC', 'CAUGCCCA', 'GCCUGGCU', 'GAGCCCG', 'AGAUUCG', 'CUCCUCCC', 'CCUCAUG', 'CCAACCCC', 'ACACAGG', 'UCCCGGC', 'CUUUUAA', 'UGUUCUU', 'UGAAUAAA', 'CACUUUA', 'UUUUCUA', 'AUAAAAUA', 'AAAAAGGA', 'AACCUU']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2657038494752847e-80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "f1=open(\"D:/bert_seq2seq/result/bert_2048_3utr.txt\",'r')\n",
    "f2=open(\"D:/bert_seq2seq/data/test/test_3utr_token_new.txt\",'r')\n",
    "pre_list=f1.readlines()\n",
    "true_list=f2.readlines()\n",
    "def bleu_score(pre_list,true_list):\n",
    "    candidates=[]\n",
    "    references=[]\n",
    "    for i in range(len(pre_list)):\n",
    "        if pre_list[i]=='' or pre_list==' ':\n",
    "            pre_list[i]='#'\n",
    "    for x in pre_list:\n",
    "        x=x.strip('\\n').strip(' ')\n",
    "        candidates.append(list(x.split(' ')))\n",
    "    for y in true_list:\n",
    "        y=y.strip('\\n').strip(' ')        \n",
    "        references.append(list(y.split(' ')))\n",
    "    print(candidates[0],references[0])\n",
    "    return corpus_bleu(references,candidates) \n",
    "bleu_score(pre_list,true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'dog', 'bit', 'the', 'man'], ['it', 'was', 'not', 'surprising'], ['the', 'man', 'had', 'just', 'bitten', 'him']] [[['the', 'dog', 'bit', 'the', 'man'], ['the', 'dog', 'had', 'bit', 'the', 'man']], [['it', 'was', 'not', 'unexpected'], ['no', 'one', 'was', 'surprised']], [['the', 'man', 'bit', 'him', 'first'], ['the', 'man', 'had', 'bitten', 'the', 'dog']]]\n",
      "Corpus BLEU: 0.5719285395120957\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "s1 = \"the dog bit the man\"\n",
    "s2 = \"the dog had bit the man\"\n",
    "\n",
    "s3 = \"it was not unexpected\"\n",
    "s4 = \"no one was surprised\"\n",
    "\n",
    "s5 = \"the man bit him first\"\n",
    "s6 = \"the man had bitten the dog\"\n",
    "\n",
    "s7 = \"the dog bit the man\"\n",
    "s8 = \"it was not surprising\"\n",
    "s9 = \"the man had just bitten him\"\n",
    "\n",
    "candidates = [list(s7.split(\" \")), list(s8.split(\" \")), list(s9.split(\" \"))]\n",
    "references = [\n",
    "    [list(s1.split(\" \")), list(s2.split(\" \"))],\n",
    "    [list(s3.split(\" \")), list(s4.split(\" \"))],\n",
    "    [list(s5.split(\" \")), list(s6.split(\" \"))]\n",
    "]\n",
    "print(candidates,references)\n",
    "print('Corpus BLEU: {}'.format(corpus_bleu(references, candidates)))\n",
    "# Corpus BLEU: 0.5719285395120957\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor维度转化（数值保留）\n",
    "import torch\n",
    "x=torch.randn(1026,640)\n",
    "# x1=x\n",
    "# y=x.repeat(28996//25)\n",
    "# z=x1.narrow(0,0,28996%25)\n",
    "# y=torch.cat((y,z),0)\n",
    "z=x.narrow(0,2,1024)\n",
    "print(x.size(),z.size())\n",
    "print(x,z)\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert.encoder.layer.0.attention.self.key.weight': 'a',\n",
       " 'bert.encoder.layer.0.attention.self.key.bias': 'b'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te=f'bert.encoder.layer.0.attention.self.key'\n",
    "di={}\n",
    "di[te+'.weight']='a'\n",
    "di[te+'.bias']='b'\n",
    "di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征提取和嵌入实现（要求输出对应维度）\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "x=torch.randn(1024)\n",
    "y=nn.Linear.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Generate a large random dataset\n",
    "rs = np.random.RandomState(33)\n",
    "d = pd.DataFrame(data=rs.normal(size=(100, 26)),\n",
    "                 columns=list(ascii_letters[26:]))\n",
    "#print(d)\n",
    "# Compute the correlation matrix\n",
    "corr = d.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(200, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
